{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54384cf3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Twitter Sentiment Analysis using LSTM\n",
    "# \n",
    "# In this project, we build an LSTM model to classify tweets into positive or negative sentiments using the Sentiment140 dataset.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# %%\n",
    "# Load dataset\n",
    "data_path = \"../data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path, encoding='latin-1', header=None)\n",
    "df = df[[0, 5]]\n",
    "df.columns = [\"sentiment\", \"text\"]\n",
    "\n",
    "# Keep only 0 (negative) and 4 (positive) sentiments\n",
    "df = df[df['sentiment'] != 2]\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
    "\n",
    "df = df.sample(100000, random_state=42).reset_index(drop=True)  # Subsample to speed up training\n",
    "\n",
    "# %%\n",
    "# Preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"http\\S+|@\\S+|#\\S+|[^A-Za-z\\s]\", \"\", text)\n",
    "    text = text.lower().strip()\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(preprocess)\n",
    "\n",
    "# %%\n",
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"cleaned\"])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df[\"cleaned\"])\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "y = df[\"sentiment\"].values\n",
    "\n",
    "# %%\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# %%\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# %%\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "# %%\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# %%\n",
    "# Predictions and confusion matrix\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
